name: Daily Event Scraping

on:
  schedule:
    # Run daily at 9 AM UTC (adjust timezone as needed)
    - cron: '0 9 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-and-post:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run event scraper
      env:
        LASTFM_API_KEY: ${{ secrets.LASTFM_API_KEY }}
        TICKETMASTER_API_KEY: ${{ secrets.TICKETMASTER_API_KEY }}
        BANDSINTOWN_APP_ID: ${{ secrets.BANDSINTOWN_APP_ID }}
        LASTFM_USERS: ${{ secrets.LASTFM_USERS }}
        DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
      run: |
        python -c "
        import os
        import requests
        import json
        from dotenv import load_dotenv
        from src.lastfm.scraper import EventScraper
        from src.utils.config import Config
        
        # Load environment variables
        load_dotenv()
        
        # Validate configuration
        Config.validate()
        
        # Get usernames to track
        usernames = Config.get_users()
        if not usernames:
            print('âŒ No usernames configured')
            exit(1)
        
        print(f'ğŸš€ Starting gutterbot scraper...')
        print(f'ğŸ“Š Tracking users: {usernames}')
        
        # Initialize scraper
        scraper = EventScraper(
            Config.get_api_key(), 
            Config.get_ticketmaster_api_key(),
            Config.get_bandsintown_app_id()
        )
        
        # Scrape and match
        import asyncio
        matches = asyncio.get_event_loop().run_until_complete(scraper.scrape_and_match(usernames))
        
        # Post to discord webhook if we have matches
        webhook_url = os.getenv('DISCORD_WEBHOOK_URL')
        if webhook_url and matches:
            for username, user_matches in matches.items():
                if not user_matches:
                    continue
                    
                # Create embed
                embed = {
                    'title': f'ğŸµ Event Recommendations for {username}',
                    'description': f'Found {len(user_matches)} events you might be interested in:',
                    'color': 0x1db954,
                    'fields': []
                }
                
                for i, (event, matched_artist, similarity) in enumerate(user_matches[:5], 1):
                    field_value = f'**Venue:** {event.venue}\n'
                    field_value += f'**Date:** {event.date}\n'
                    field_value += f'**Matched Artist:** {matched_artist} ({similarity:.0%} match)\n'
                    
                    if event.artists:
                        artists_str = ', '.join(event.artists[:3])
                        if len(event.artists) > 3:
                            artists_str += f' +{len(event.artists) - 3} more'
                        field_value += f'**Artists:** {artists_str}\n'
                    
                    if event.url:
                        field_value += f'**Tickets:** [Get Tickets]({event.url})'
                    
                    embed['fields'].append({
                        'name': f'{i}. {event.title}',
                        'value': field_value,
                        'inline': False
                    })
                
                # Send webhook
                payload = {'embeds': [embed]}
                response = requests.post(webhook_url, json=payload)
                if response.status_code == 204:
                    print(f'âœ… Posted {len(user_matches)} events for {username}')
                else:
                    print(f'âŒ Failed to post events for {username}: {response.status_code}')
        else:
            print('ğŸµ No matches found or no webhook configured')
        "

